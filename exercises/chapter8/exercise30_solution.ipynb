{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 30 Solution - Diffusion models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is based on the code from the [Hugging Face Diffusion Models Course](https://huggingface.co/learn/diffusion-course/en/unit1/3#conclusions) by Jonathan Whitaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Train a diffusion model for data generation using a fiber microstructure dataset\n",
    "\n",
    "### Learning goals\n",
    "- Understand how a diffusion model works (including the noising and denoising process)\n",
    "- Familiarize yourself with the implementation of a diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data generation parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "domainLength = 1\n",
    "numberOfCircles = 5\n",
    "radius = 0.12\n",
    "min_max_side_length = (0.8, 0.8)\n",
    "\n",
    "numberOfSamples = 1280  #12800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 20\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**helper functions to generate dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNonOverlappingCirclesInDomain(N, domainLength, numberOfCircles, radius):\n",
    "    domain = np.ones((N, N))\n",
    "    x = np.linspace(0, domainLength, N)\n",
    "    y = np.linspace(0, domainLength, N)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    for i in range(numberOfCircles):\n",
    "        overlap = True\n",
    "        while overlap == True:\n",
    "            xc = np.random.uniform(radius, domainLength - radius)\n",
    "            yc = np.random.uniform(radius, domainLength - radius)\n",
    "\n",
    "            mask = (x - xc) ** 2 + (y - yc) ** 2 < radius ** 2\n",
    "            if ~np.any(domain[mask] == 0):\n",
    "                overlap = False\n",
    "        domain[mask] = 0\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)    # Ensure the data directory exists\n",
    "\n",
    "samples = torch.zeros((numberOfSamples, 1, N, N))\n",
    "for i in range(numberOfSamples):\n",
    "    samples[i, 0] = torch.from_numpy(\n",
    "        generateNonOverlappingCirclesInDomain(N, domainLength, numberOfCircles, radius)).to(torch.float32)\n",
    "torch.save(samples, f\"data/normalData{N}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**visualize the first 5 generated microstructures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5)\n",
    "for i, ax in enumerate(axes):\n",
    "    sample = samples[i].squeeze()\n",
    "    ax.imshow(sample, cmap='jet')\n",
    "    ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load generated data into PyTorch dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class microstructureDataset(Dataset):\n",
    "    def __init__(self, data, labels=None, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        if self.labels is None:\n",
    "            return sample, 0\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataset instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('data/normalData64.pt', weights_only=False)\n",
    "#labels = torch.load('data/shapeLabels64.pt', weights_only=False) # TODO ask moritz?\n",
    "dataset = microstructureDataset(data[1:12800])\n",
    "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**visualize part of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataloader))  # TODO ask Moritz what y is?\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(10, 1.5))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(x[i][0].cpu(), cmap='jet')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data corruption through noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**helper function defining the noising process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt(x, amount):\n",
    "    \"\"\"Corrupt the input `x` by mixing it with noise according to `amount`\"\"\"\n",
    "    noise = torch.rand_like(x)\n",
    "    amount = amount.view(-1, 1, 1, 1)  # Sort shape so broadcasting works\n",
    "    return x * (1 - amount) + noise * amount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**visualization of the noising process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = torch.linspace(0, 1, x.shape[0])  # Left to right -> more corruption\n",
    "noised_x = corrupt(x, amount)\n",
    "print(\"noising amount: \" + str(amount.data))\n",
    "\n",
    "t_labels = [f'{i}' for i in range(7)]\n",
    "t_labels.append('T')\n",
    "print(\"labels: \" + str(t_labels))\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(15, 3))\n",
    "for i in range(8):\n",
    "    axes[i].imshow(noised_x[i][0], cmap='jet')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "axes[0].set_title(r'$t = 0$')\n",
    "axes[1].set_title(r'$t = 1$')\n",
    "axes[2].set_title(r'$t = 2$')\n",
    "axes[3].set_title(r'$\\dots$')\n",
    "axes[6].set_title(r'$\\dots$')\n",
    "axes[7].set_title(r'$t = T$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the noise amount approaches one, our data begins to look like pure random noise. But for most noise amounts, you can guess the fiberd distribution fairly well. Do you think this is optimal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network architecture definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUNet(nn.Module):\n",
    "    \"\"\"A minimal UNet implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.down_layers = torch.nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "        ])\n",
    "        self.up_layers = torch.nn.ModuleList([\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2),\n",
    "        ])\n",
    "        self.act = nn.SiLU()  # The activation function\n",
    "        self.downscale = nn.MaxPool2d(2)\n",
    "        self.upscale = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = []\n",
    "        for i, l in enumerate(self.down_layers):\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "            if i < 2:  # For all but the third (final) down layer:\n",
    "                h.append(x)  # Storing output for skip connection\n",
    "                x = self.downscale(x)  # Downscale ready for the next layer\n",
    "\n",
    "        for i, l in enumerate(self.up_layers):\n",
    "            if i > 0:  # For all except the first up layer\n",
    "                x = self.upscale(x)  # Upscale\n",
    "                x += h.pop()  # Fetching stored output (skip connection)\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**neural network instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BasicUNet()\n",
    "net.to(device)\n",
    "random_noise = torch.rand(8, 1, N, N)\n",
    "print(\"number of parameters: \" + str(sum([p.numel() for p in net.parameters()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loss function, optimizer and history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        # Get some data and prepare the corrupted version\n",
    "        x = x.to(device)  # Data on the GPU\n",
    "        noise_amount = torch.rand(x.shape[0]).to(device)  # Pick random noise amounts\n",
    "        noisy_x = corrupt(x, noise_amount)  # Create our noisy x\n",
    "\n",
    "        # Get the model prediction\n",
    "        pred = net(noisy_x)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(pred, x)  # How close is the output to the true 'clean' x?\n",
    "\n",
    "        # Backprop and update the params:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Store the loss for later\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Print our the average of the loss values for this epoch:\n",
    "    avg_loss = sum(losses[-len(train_dataloader):]) / len(train_dataloader)\n",
    "    print(f'Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cost history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel(\"epochs\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**visualization of model predictions from the corrupted data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch some data\n",
    "x, y = next(iter(train_dataloader))\n",
    "x = x[:8]  # Only using the first 8 for easy plotting\n",
    "\n",
    "# Corrupt with a range of amounts\n",
    "amount = torch.linspace(0, 1, x.shape[0])  # Left to right -> more corruption\n",
    "noised_x = corrupt(x, amount)\n",
    "\n",
    "# Get the model predictions\n",
    "with torch.no_grad():\n",
    "    preds = net(noised_x.to(device)).detach().cpu()\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 7))\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0].clip(0, 1), cmap='gray')\n",
    "axs[1].set_title('Corrupted data')\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0].clip(0, 1), cmap='gray')\n",
    "axs[2].set_title('Network Predictions')\n",
    "axs[2].imshow(torchvision.utils.make_grid(preds)[0].clip(0, 1), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of noising process (through corruption) and denoising process (through neural network)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 8, figsize=(10, 2))\n",
    "\n",
    "for i in range(8):\n",
    "    axes[i].imshow(noised_x[i][0], cmap='jet')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "axes[0].set_title(r'$t = 0$')\n",
    "axes[1].set_title(r'$t = 1$')\n",
    "axes[2].set_title(r'$t = 2$')\n",
    "axes[3].set_title(r'$\\dots$')\n",
    "axes[6].set_title(r'$\\dots$')\n",
    "axes[7].set_title(r'$t = T$')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Get the model predictions\n",
    "with torch.no_grad():\n",
    "    preds = net(noised_x.to(device)).detach().cpu()\n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(10, 2))\n",
    "\n",
    "for i in range(8):\n",
    "    axes[i].imshow(preds[i][0], cmap='jet', vmin=0, vmax=1)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of the mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3\n",
    "x = torch.rand(8, 1, N, N).to(device)  # Start from random\n",
    "step_history = [x.detach().cpu()]\n",
    "pred_output_history = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        pred = net(x)  # Predict the denoised x0\n",
    "    pred_output_history.append(pred.detach().cpu())  # Store model output for plotting\n",
    "    mix_factor = 1 / (n_steps - i)  # How much we move towards the prediction\n",
    "    x = x * (1 - mix_factor) + pred * mix_factor  # Move part of the way there\n",
    "    step_history.append(x.detach().cpu())  # Store step for plotting\n",
    "\n",
    "fig, axs = plt.subplots(n_steps, 2, figsize=(10, 7), sharex=True)\n",
    "axs[0, 0].set_title('x (model input)')\n",
    "axs[0, 1].set_title('model prediction')\n",
    "for i in range(n_steps):\n",
    "    axs[i, 0].imshow(torchvision.utils.make_grid(step_history[i])[0].clip(0, 1), cmap='gray')\n",
    "    axs[i, 1].imshow(torchvision.utils.make_grid(pred_output_history[i])[0].clip(0, 1), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generation of 64 new samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 40\n",
    "x = torch.rand(64, 1, N, N).to(device)\n",
    "for i in range(n_steps):\n",
    "    noise_amount = torch.ones((x.shape[0],)).to(device) * (1 - (i / n_steps))  # Starting high going low\n",
    "    with torch.no_grad():\n",
    "        pred = net(x)\n",
    "    mix_factor = 1 / (n_steps - i)\n",
    "    x = x * (1 - mix_factor) + pred * mix_factor\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax.imshow(torchvision.utils.make_grid(x.detach().cpu(), nrow=8)[0].clip(0, 1), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
