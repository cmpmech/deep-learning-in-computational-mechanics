{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ba11a8-9964-4b7e-b262-8b631b887188",
   "metadata": {},
   "source": [
    "# Exercise 16 - Normalization and Weighting\n",
    "### Task\n",
    "This is a modified file from exercise 14 (Code blocks with changes are indicated in <font color='red'>**red**</font>). The difference lies in the scaling of the solution with `scaleSolution` and of the differential equation with `scaleODE`.\n",
    "1. What occurs when you increase and decrease these factors?\n",
    "2. A weight for the boundary loss is introduced as `boundaryLossWeight`. Can you counteract the previously encountered effects by tuning this weight?\n",
    "\n",
    "### Learning goals\n",
    "- Understand the impact of the solution's and differential equation's scale\n",
    "- Experience how weighting terms change the convergence of the training algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc65ef-fdb0-409a-8b58-6ee22a3a38db",
   "metadata": {},
   "source": [
    "**import libraries & set seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfeb949-ac58-4b07-9687-c41064b91f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.388552909Z",
     "start_time": "2024-01-30T15:43:10.353712900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6a05eb60064b2",
   "metadata": {},
   "source": [
    "<font color='red'>**scaling**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab33c07a361fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleODE = 1  # [1, 1e-3]\n",
    "scaleSolution = 1  # [0.5, 5]\n",
    "boundaryLossWeight = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287a8dc-3ef0-490c-a549-a4c06474f8b9",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837a3c0-c7e6-4750-94d6-07b83721493f",
   "metadata": {},
   "source": [
    "**gradient computation with automatic differentiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ff7cc-b51d-4a65-b314-06d55506104a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.408190483Z",
     "start_time": "2024-01-30T15:43:10.392400212Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDerivative(y, x, n):\n",
    "    \"\"\"Compute the nth order derivative of y = f(x) with respect to x.\"\"\"\n",
    "\n",
    "    if n == 0:\n",
    "        return y\n",
    "    else:\n",
    "        dy_dx = grad(\n",
    "            y, x, torch.ones(x.size()[0], 1), create_graph=True, retain_graph=True\n",
    "        )[0]\n",
    "        return getDerivative(dy_dx, x, n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351b4bd-8953-4816-87ac-fd5abb029b75",
   "metadata": {},
   "source": [
    "**neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa82fc-8100-4a35-9709-9f3ff1272515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.420365745Z",
     "start_time": "2024-01-30T15:43:10.410427620Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputDimension,\n",
    "        hiddenDimensions,\n",
    "        outputDimension,\n",
    "        activationFunction=torch.nn.Tanh(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        modules.append(torch.nn.Linear(inputDimension, hiddenDimensions[0]))\n",
    "        modules.append(activationFunction)\n",
    "        for i in range(len(hiddenDimensions) - 1):\n",
    "            modules.append(\n",
    "                torch.nn.Linear(hiddenDimensions[i], hiddenDimensions[i + 1])\n",
    "            )\n",
    "            modules.append(activationFunction)\n",
    "        modules.append(torch.nn.Linear(hiddenDimensions[-1], outputDimension))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997a44b-2089-42b8-b3cc-dcb75599c2d7",
   "metadata": {},
   "source": [
    "**initialization of neural network weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccef84d-eadf-4dc1-8298-b1062faa5f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.441081765Z",
     "start_time": "2024-01-30T15:43:10.420588657Z"
    }
   },
   "outputs": [],
   "source": [
    "def initWeights(m):\n",
    "    \"\"\"Initialize weights of neural network with xavier initialization.\"\"\"\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            m.weight, gain=torch.nn.init.calculate_gain(\"tanh\")\n",
    "        )  # adapt if using a different initialization\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac280a6c-0742-4bf8-b6f2-0995b3680079",
   "metadata": {},
   "source": [
    "## PINN helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551c1ad-ef82-4af5-bc7c-658fb6d16913",
   "metadata": {},
   "source": [
    "**displacement computation**\n",
    "$$\\hat{u}=F_{NN}(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eda658-51ba-47bc-a7ff-ed2bb47c4c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.441470921Z",
     "start_time": "2024-01-30T15:43:10.420668583Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDisplacements(model, x):\n",
    "    return model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9999f25-b7e7-42fa-a1bd-4824a0a32fa3",
   "metadata": {},
   "source": [
    "**loss term computation**\n",
    "\n",
    "The differential equation loss\n",
    "$$\\mathcal{L}_R=\\sum_{i=1}^N\\bigl(\\frac{d}{dx}EA\\bigl(\\frac{d\\hat{u}}{dx}\\bigr)+p\\bigr)^2$$\n",
    "The boundary condition loss \n",
    "$$\\mathcal{L}_B=\\sum_{i=1}^{N_B}\\bigl( \\frac{d^{n_i} \\hat{u}}{dx^{n_i}} - F \\bigr)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e36d4-ee7e-4450-8c50-a4ba4fd101e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.459473934Z",
     "start_time": "2024-01-30T15:43:10.440877807Z"
    }
   },
   "outputs": [],
   "source": [
    "def getLossTerms(x, xB, u, uB, EA, distLoad, uBLabel):\n",
    "    differentialEquationLoss = (\n",
    "        getDerivative(EA * getDerivative(u, x, 1), x, 1) + distLoad\n",
    "    )\n",
    "    differentialEquationLoss = torch.sum(differentialEquationLoss**2).squeeze()\n",
    "\n",
    "    # initialization\n",
    "    boundaryConditionLoss = 0\n",
    "\n",
    "    for i in range(len(uBLabel)):\n",
    "        boundaryConditionLoss += (\n",
    "            getDerivative(uB, xB, uBLabel[i][1])[i] - uBLabel[i][0]\n",
    "        ).squeeze() ** 2\n",
    "\n",
    "    return differentialEquationLoss, boundaryConditionLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a48beb-255a-4042-b29b-bdf06a4cdd3a",
   "metadata": {},
   "source": [
    "<font color='red'>**cost function computation**</font>\n",
    "$$C=\\mathcal{L}_R+\\kappa_B\\mathcal{L}_B$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbab3de-4767-45c9-a4d3-6bfb638d243a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.462320563Z",
     "start_time": "2024-01-30T15:43:10.459360374Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCostFunction(lossTerms, boundaryLossWeight):\n",
    "    return lossTerms[0] + boundaryLossWeight * lossTerms[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e7265-83d4-4be6-b5d2-018649c32b21",
   "metadata": {},
   "source": [
    "## Problem setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957569f-3de2-43dd-9b11-3221bf3d04b9",
   "metadata": {},
   "source": [
    "<font color='red'>**physical parameters**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7459465-221f-43d6-8c9f-0d7ff6938496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.478653369Z",
     "start_time": "2024-01-30T15:43:10.475138192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Analytial solution\n",
    "uAnalytic = lambda x: (1.0 - np.cos(3.0 * np.pi * x)) * scaleSolution\n",
    "\n",
    "# Problem data\n",
    "E = lambda x: 1.0 * scaleODE / scaleSolution  # Young's modulus\n",
    "A = lambda x: x**2 + 1.0  # cross-sectional area\n",
    "L = 3.0 / 2.0  # bar length\n",
    "uB = [\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "]  # boundary conditions: [value, degree of differentiation, coordinate]\n",
    "distLoad = (\n",
    "    lambda x: (\n",
    "        -6 * x * np.pi * torch.sin(3 * np.pi * x)\n",
    "        - 9 * (x**2 + 1) * np.pi**2 * torch.cos(3 * np.pi * x)\n",
    "    )\n",
    "    * scaleODE\n",
    ")  # distributed load p(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f533b6-272e-460a-8355-0850025d400f",
   "metadata": {},
   "source": [
    "**hyperparameters**\n",
    "\n",
    "currently Adam is selected as optimizer. By commenting the Adam block and uncommenting the LBFGS block, you can enable LBFGS as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15917078-13cb-4725-9164-cf409ada9530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.479012559Z",
     "start_time": "2024-01-30T15:43:10.475224009Z"
    }
   },
   "outputs": [],
   "source": [
    "Nx = 100  # number of collocation points\n",
    "hiddenDimensions = [100]  # definition of hidden layers\n",
    "activationFunction = (\n",
    "    torch.nn.Tanh()\n",
    ")  # if this is changed, also adapt the initialization\n",
    "\n",
    "epochs = 5000  # 5000  # number of epochs\n",
    "lr = 5e-3  # learning rate\n",
    "selectOptimizer = \"Adam\"\n",
    "\n",
    "# epochs = 500\n",
    "# selectOptimizer = \"LBFGS\"\n",
    "# lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309db2e-aa72-4e72-bbd5-0d1df04fa0bf",
   "metadata": {},
   "source": [
    "**neural network & optimizer setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66f248-a5c1-4ca7-8552-41ffbe2e7828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.506695593Z",
     "start_time": "2024-01-30T15:43:10.478480395Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NN(1, hiddenDimensions, 1, activationFunction)\n",
    "model.apply(initWeights)\n",
    "if selectOptimizer == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "elif selectOptimizer == \"LBFGS\":\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2fddfc-395b-4339-bebe-6558fde75679",
   "metadata": {},
   "source": [
    "**training grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8609cae-76eb-450e-9b84-75a69068c7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:10.509663812Z",
     "start_time": "2024-01-30T15:43:10.506949947Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(0, L, Nx, requires_grad=True).unsqueeze(1)\n",
    "\n",
    "# boundary points\n",
    "xB = torch.tensor([uBi[2] for uBi in uB]).unsqueeze(1).to(torch.float32)\n",
    "xB.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f755e-e923-49d3-954c-bf09cd8ee74d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bca03-41d4-4a84-9945-326f7f59c3a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:19.951680882Z",
     "start_time": "2024-01-30T15:43:10.507065611Z"
    }
   },
   "outputs": [],
   "source": [
    "differentialEquationLossHistory = np.zeros(epochs)\n",
    "boundaryConditionLossHistory = np.zeros(epochs)\n",
    "costHistory = np.zeros(epochs)\n",
    "\n",
    "start = time.perf_counter()\n",
    "start0 = start\n",
    "for epoch in range(epochs):\n",
    "    # predict displacements\n",
    "    uPred = getDisplacements(model, x)\n",
    "    uBPred = getDisplacements(model, xB)\n",
    "\n",
    "    lossTerms = getLossTerms(x, xB, uPred, uBPred, E(x) * A(x), distLoad(x), uB)\n",
    "    differentialEquationLossHistory[epoch] = lossTerms[0].detach()\n",
    "    boundaryConditionLossHistory[epoch] = lossTerms[1].detach()\n",
    "    costHistory[epoch] = getCostFunction(\n",
    "        lossTerms, 1\n",
    "    ).detach()  # here the boundary weight is set to 1 to estimate true cost\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        uPred = getDisplacements(model, x)\n",
    "        uBPred = getDisplacements(model, xB)\n",
    "        lossTerms = getLossTerms(x, xB, uPred, uBPred, E(x) * A(x), distLoad(x), uB)\n",
    "        cost = getCostFunction(lossTerms, boundaryLossWeight)\n",
    "        cost.backward(retain_graph=True)\n",
    "        return cost\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        elapsedTime = (time.perf_counter() - start) / 100\n",
    "        string = \"Epoch: {}/{}\\t\\tDifferential equation loss = {:2e}\\t\\tBoundary condition closs = {:2e}\\nCost = {:2e}\\t\\tElapsed time = {:2f}\"\n",
    "        # Format string and print\n",
    "        print(\n",
    "            string.format(\n",
    "                epoch,\n",
    "                epochs - 1,\n",
    "                differentialEquationLossHistory[epoch],\n",
    "                boundaryConditionLossHistory[epoch],\n",
    "                costHistory[epoch],\n",
    "                elapsedTime,\n",
    "            )\n",
    "        )\n",
    "        start = time.perf_counter()\n",
    "elapsedTime = time.perf_counter() - start0\n",
    "string = \"Total elapsed time: {:2f}\\nAverage elapsed time per epoch: {:2f}\"\n",
    "print(string.format(elapsedTime, elapsedTime / epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e63a9d-ea31-4930-90bb-b429637ca35c",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b677c7-9d31-4451-8562-8aa347e04726",
   "metadata": {},
   "source": [
    "**training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6c235-0210-40aa-a4d4-b93afc51989f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:20.237070954Z",
     "start_time": "2024-01-30T15:43:19.961240265Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Cost function $C$\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.plot(costHistory, \"k\", linewidth=2, label=\"Cost $C$\")\n",
    "ax.plot(\n",
    "    differentialEquationLossHistory,\n",
    "    \"r:\",\n",
    "    linewidth=2,\n",
    "    label=\"Differential equation loss $\\\\mathcal{L}_{\\\\mathcal{N}}$\",\n",
    ")\n",
    "ax.plot(\n",
    "    boundaryConditionLossHistory,\n",
    "    \"b--\",\n",
    "    linewidth=2,\n",
    "    label=\"Boundary condition loss $\\\\mathcal{L}_{\\\\mathcal{B}}$\",\n",
    ")\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f6de0-2ef2-4c1d-bad3-714c954ac14f",
   "metadata": {},
   "source": [
    "**displacement prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd55fa0-2d9e-4e79-be43-3f4164db12ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:43:20.413440220Z",
     "start_time": "2024-01-30T15:43:20.242031854Z"
    }
   },
   "outputs": [],
   "source": [
    "xTest = torch.linspace(0, L, 1000).unsqueeze(1)\n",
    "uPredTest = getDisplacements(model, xTest).detach()\n",
    "uPred = getDisplacements(model, x).detach()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"displacement $u$\")\n",
    "ax.plot(xTest, uAnalytic(xTest), \"gray\", linewidth=2, label=\"analytical solution\")\n",
    "ax.plot(xTest, uPredTest, \"k:\", linewidth=2, label=\"prediction\")\n",
    "ax.plot(x.detach(), uPred, \"rs\", markersize=6, label=\"collocation points\")\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
