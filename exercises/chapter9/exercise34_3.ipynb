{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffbf192-4ba9-4aa9-a90a-4974e829bc39",
   "metadata": {},
   "source": [
    "# Exercise 34 (3) - Data-Driven Solver: train the surrogate\n",
    "\n",
    "With the generated data and the identified reduced basis for the wave pressures, train a surrogate model as data-driven solver. The neural network architecture can be specified with `selectModel` as either a fully connected or a convolutional neural network. Try to improve the performance by adjusting the hyperparameters.\n",
    "\n",
    "### Learning goals\n",
    "- Familiarize yourself with data-driven deep learning training workflows with tools, such as DataSet, DataLoader\n",
    "- Understand how dimensionality reduction techniques can be combined with a deep learning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce013e-5489-4095-8050-bd23f7b9b729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:30.644938Z",
     "start_time": "2024-10-24T05:58:30.642360Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fc2062a7fa73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:30.792417Z",
     "start_time": "2024-10-24T05:58:30.786329Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15a3ef45f8dc4e",
   "metadata": {},
   "source": [
    "## Select neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b57a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectModel = \"FNN\"\n",
    "#selectModel = \"CNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee159d27",
   "metadata": {},
   "source": [
    "## Neural network helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b81423",
   "metadata": {},
   "source": [
    "**weight initialization, normalization for convolutional layers & transformation from convolutional to fully connected layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"Initialize weights of neural network with xavier initialization.\"\"\"\n",
    "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv1d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=torch.nn.init.calculate_gain('leaky_relu', 0.2))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class PixelNorm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.sum(x ** 2, axis=(2), keepdim=True) / x.shape[2] + 1e-8)\n",
    "\n",
    "\n",
    "class SqueezeToFNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.reshape((len(x), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6ed3b",
   "metadata": {},
   "source": [
    "**fully connected neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        modules.append(torch.nn.Linear(100, 100))\n",
    "        modules.append(torch.nn.ReLU())\n",
    "        modules.append(torch.nn.Linear(100, 100))\n",
    "        modules.append(torch.nn.ReLU())\n",
    "        modules.append(torch.nn.Linear(100, 100))\n",
    "        modules.append(torch.nn.ReLU())\n",
    "        modules.append(torch.nn.Linear(100, 100))\n",
    "        modules.append(torch.nn.ReLU())\n",
    "        modules.append(torch.nn.Linear(100, 3))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN()\n",
    "model(torch.randn(3, 2, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb4e8b",
   "metadata": {},
   "source": [
    "**convolutional neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        modules.append(torch.nn.Conv1d(4, 8, kernel_size=3, stride=1, padding=0, device=device))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.PReLU(init=0.2, device=device))\n",
    "        modules.append(torch.nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(8, 16, kernel_size=3, stride=1, padding=0, device=device))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.PReLU(init=0.2, device=device))\n",
    "        modules.append(torch.nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(16, 8, kernel_size=3, stride=1, padding=0, device=device))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.PReLU(init=0.2, device=device))\n",
    "        modules.append(torch.nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(8, 4, kernel_size=3, stride=1, padding=0, device=device))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.PReLU(init=0.2, device=device))\n",
    "        modules.append(torch.nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.append(SqueezeToFNN())\n",
    "\n",
    "        modules.append(torch.nn.Linear(164, 100, device=device))\n",
    "        modules.append(torch.nn.PReLU(init=0.2, device=device))\n",
    "        modules.append(torch.nn.Linear(100, 100, device=device))\n",
    "        modules.append(torch.nn.PReLU(init=0.2, device=device))\n",
    "        modules.append(torch.nn.Linear(100, 3, device=device))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933854f8",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca66bb2",
   "metadata": {},
   "source": [
    "**loading settings of measurements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = pd.read_csv(\"dataset1DFWI/settings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417243c",
   "metadata": {},
   "source": [
    "**load data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet.FullWaveFormInversionDataset1D(settings, device)\n",
    "datasetTraining, datasetValidation = torch.utils.data.random_split(dataset, [0.9, 0.1],\n",
    "                                                                   generator=torch.Generator().manual_seed(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f4b8a9",
   "metadata": {},
   "source": [
    "## Hyperparameter selection, data preperation & model inititialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60edf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectModel == \"FNN\":\n",
    "    model = FNN()\n",
    "\n",
    "    SVDBasisU = torch.load(\"dataset1DFWI/measurementBasis.pt\", weights_only=True)\n",
    "\n",
    "    # hyperparameters\n",
    "    lr = 1e-2\n",
    "    batchSize = 256\n",
    "    alpha = -0.5\n",
    "    beta = 0.2\n",
    "    epochs = 400  #300\n",
    "    clip = 1e-2\n",
    "    l2 = 1e-6\n",
    "\n",
    "elif selectModel == \"CNN\":\n",
    "    model = CNN()\n",
    "\n",
    "    # hyperparameters\n",
    "    lr = 4e-3  #1e-2 #1e-2 #1e-2\n",
    "    batchSize = 256\n",
    "    alpha = -0.5\n",
    "    beta = 0.2\n",
    "    epochs = 400\n",
    "    clip = 1e-2\n",
    "    l2 = 1e-6\n",
    "\n",
    "print(\"number of parameters: {:d}\".format(\n",
    "    np.sum(np.array([len(list(model.parameters())[i].flatten()) for i in range(len(list(model.parameters())))]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e86fae",
   "metadata": {},
   "source": [
    "**define dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaderTraining = DataLoader(datasetTraining, batch_size=batchSize)\n",
    "dataloaderValidation = DataLoader(datasetValidation, batch_size=len(datasetValidation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65287a06",
   "metadata": {},
   "source": [
    "## Optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705423bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=l2)\n",
    "\n",
    "lr_lambda = lambda epoch: (beta * epoch + 1) ** alpha\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1dfc87",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc061ebd",
   "metadata": {},
   "source": [
    "**training setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingCostHistory = np.zeros(epochs)\n",
    "validationCostHistory = np.zeros(epochs)\n",
    "start = time.perf_counter()\n",
    "start0 = start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd61d4a",
   "metadata": {},
   "source": [
    "**training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataloaderTraining))"
    "print(sample[0].shape)\n",
    "print(SVDBasisU.shape)\n",
    "print((sample[0] @ SVDBasisU.t()).shape)\n",
    "print((sample[0] @ SVDBasisU.t()).reshape((-1, 10)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch, sample in enumerate(dataloaderTraining):\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if selectModel == \"FNN\":\n",
    "            coeffPred = model((sample[0] @ SVDBasisU.t()).reshape((-1, 100)))\n",
    "        elif selectModel == \"CNN\":\n",
    "            coeffPred = model(sample[0].reshape((-1, 4, settings.N[0] + 1))) \n",
    "\n",
    "        cost = 0.5 * torch.mean((coeffPred - sample[2]) ** 2)\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        trainingCostHistory[epoch] += cost.detach()\n",
    "\n",
    "    trainingCostHistory[epoch] /= (batch + 1)\n",
    "\n",
    "    model.eval()\n",
    "    sample = next(iter(dataloaderValidation))\n",
    "\n",
    "    if selectModel == \"FNN\":\n",
    "        coeffPred = model(\n",
    "            (sample[0] @ SVDBasisU.t()).reshape((-1, 100))) \n",
    "    elif selectModel == \"CNN\":\n",
    "        coeffPred = model(sample[0].reshape((-1, 4, settings.N[0] + 1)))\n",
    "\n",
    "    validationCostHistory[epoch] = 0.5 * torch.mean((coeffPred - sample[2]) ** 2)\n",
    "\n",
    "    if (epoch % 10 == 0):\n",
    "        elapsed_time = time.perf_counter() - start\n",
    "        string = \"Epoch: {}/{}\\t\\tTraining Cost: {:.3E}\\t\\tValidation Cost: {:.3E}\\nElapsed time: {:2f}\"\n",
    "        print(string.format(epoch, epochs - 1, trainingCostHistory[epoch], validationCostHistory[epoch], elapsed_time))\n",
    "        start = time.perf_counter()\n",
    "\n",
    "print(\"Total elapsed training time: {:2f}\".format(time.perf_counter() - start0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d136de",
   "metadata": {},
   "source": [
    "**prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sample = next(iter(dataloaderValidation))\n",
    "if selectModel == \"FNN\":\n",
    "    coeffPred = model((sample[0] @ SVDBasisU.t()).reshape((-1, 100))) \n",
    "elif selectModel == \"CNN\":\n",
    "    coeffPred = model(sample[0].reshape((-1, 4, settings.N[0] + 1))).squeeze() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674dac5",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217cb99",
   "metadata": {},
   "source": [
    "**helper to transform prediction to grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb30422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMaterialFromCoefficients(coeff, dataset, settings):\n",
    "    Lx = settings.Lx[0]\n",
    "    Nx = settings.Nx[0]\n",
    "    c0 = settings.c0[0]\n",
    "    x = np.linspace(0, Lx, Nx + 1)\n",
    "\n",
    "    coeff = DataSet.Denormalize(coeff, dataset.Coeffnorm).detach().numpy()\n",
    "    c = x * 0 + c0\n",
    "    c[(x > coeff[0]) & (x < coeff[1])] = coeff[2]\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579843e4",
   "metadata": {},
   "source": [
    "**grid creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b811777",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx = settings.Lx[0]\n",
    "Nx = settings.Nx[0]\n",
    "x = np.linspace(0, Lx, Nx + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b2d13",
   "metadata": {},
   "source": [
    "**prediction visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3723c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(7, 6))\n",
    "\n",
    "for i in range(9):\n",
    "    i_ = int(np.floor(i / 3))\n",
    "    j_ = i % 3\n",
    "\n",
    "    cpred = generateMaterialFromCoefficients(coeffPred[i], dataset, settings)\n",
    "    ctrue = generateMaterialFromCoefficients(sample[2][i], dataset, settings)\n",
    "\n",
    "    ax[i_, j_].plot(x, ctrue, 'k', linewidth=3)\n",
    "    ax[i_, j_].plot(x, cpred, 'r--', linewidth=3)\n",
    "    ax[i_, j_].set_xticks([])\n",
    "    ax[i_, j_].set_yticks([])\n",
    "    ax[i_, j_].set_ylim([0, settings.c0[0] * 1.1])\n",
    "\n",
    "ax[0, 0].plot([0], [0], 'k', linewidth=3, label=\"ground truth\")\n",
    "ax[0, 0].plot([0], [0], 'r--', linewidth=3, label=\"prediction\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.92)\n",
    "fig.subplots_adjust(bottom=0.02)\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.015), fancybox=True, ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ed458",
   "metadata": {},
   "source": [
    "**learning history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainingCostHistory, 'k', label=\"training\")\n",
    "ax.plot(validationCostHistory, 'r', label=\"validation\")\n",
    "ax.grid()\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
