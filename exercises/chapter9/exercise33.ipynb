{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffbf192-4ba9-4aa9-a90a-4974e829bc39",
   "metadata": {},
   "source": [
    "# Exercise 33 - Iterative Forward Solver\n",
    "### Task\n",
    "Compare the effect of a linear, a fully connected neural network, and a convolutional neural network ansatz on the inversion quality of a physics-informed neural network for full waveform inversion. The ansatz is defined via `selectModel`. If necessary, adjust the number of epochs. \n",
    "\n",
    "### Learning goals\n",
    "- Familiarize yourself with the syntax of the iterative forward solver for full waveform inversion\n",
    "- Gain intuition about the three ansatz formulations for the material distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce013e-5489-4095-8050-bd23f7b9b729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:30.644938Z",
     "start_time": "2024-10-24T05:58:30.642360Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ad822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FiniteDifference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fc2062a7fa73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:30.792417Z",
     "start_time": "2024-10-24T05:58:30.786329Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15a3ef45f8dc4e",
   "metadata": {},
   "source": [
    "## Select material distribution ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef37d61767e38b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T05:58:31.064885Z",
     "start_time": "2024-10-24T05:58:31.062284Z"
    }
   },
   "outputs": [],
   "source": [
    "selectModel = \"Linear\"\n",
    "#selectModel = \"FNN\"\n",
    "#selectModel = \"CNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d004f98",
   "metadata": {},
   "source": [
    "## Ansatz helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33137e",
   "metadata": {},
   "source": [
    "**weight initialization and normalization for convolutional layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"Initialize weights of neural network with xavier initialization.\"\"\"\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=torch.nn.init.calculate_gain('leaky_relu', 0.2))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class PixelNorm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.sum(x ** 2, axis=(2), keepdim=True) / x.shape[2] + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabc2f9",
   "metadata": {},
   "source": [
    "**linear ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAnsatz(torch.nn.Module):\n",
    "    def __init__(self, Nx, device, init=1.):\n",
    "        super().__init__()\n",
    "        self.coefficients = torch.nn.Parameter(torch.ones((1, 1, Nx + 3), device=device) * init)\n",
    "\n",
    "    def forward(self, dummy):\n",
    "        return self.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dfe59f",
   "metadata": {},
   "source": [
    "**fully connected neural network ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99862315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(torch.nn.Module):\n",
    "    def __init__(self, input_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        modules.append(torch.nn.Linear(input_dimension, hidden_dimension[0]))\n",
    "        modules.append(torch.nn.LeakyReLU(inplace=True))\n",
    "        for i in range(len(hidden_dimension) - 1):\n",
    "            modules.append(torch.nn.Linear(hidden_dimension[i], hidden_dimension[i + 1]))\n",
    "            modules.append(torch.nn.PReLU(init=0.2))\n",
    "\n",
    "        modules.append(torch.nn.Linear(hidden_dimension[-1], output_dimension))\n",
    "\n",
    "        # Scale output between 0 and 1 with Sigmoid\n",
    "        modules.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze().unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853f2c7",
   "metadata": {},
   "source": [
    "**convolutional neural network ansatz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        modules.append(torch.nn.Conv1d(128, 64, kernel_size=3, padding=1, stride=1))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.PReLU(init=0.2))\n",
    "        modules.append(torch.nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(64, 32, kernel_size=3, padding=1, stride=1))\n",
    "        modules.append(PixelNorm())\n",
    "        modules.append(torch.nn.PReLU(init=0.2))\n",
    "        modules.append(torch.nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(32, 16, kernel_size=3, padding=1, stride=1))\n",
    "        modules.append(torch.nn.PReLU(init=0.2))\n",
    "        modules.append(PixelNorm())\n",
    "\n",
    "        modules.append(torch.nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(16, 1, kernel_size=3, padding=1, stride=1))\n",
    "\n",
    "        # Scale output between 0 and 1 with Sigmoid\n",
    "        modules.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77cedf3",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0898a6",
   "metadata": {},
   "source": [
    "**loading settings of measurement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = pd.read_csv(\"measurement1DFWI/settings.csv\")\n",
    "\n",
    "Lx = settings.Lx[0]\n",
    "Nx = settings.Nx[0]\n",
    "dx = Lx / Nx\n",
    "dt = settings.dt[0]\n",
    "N = settings.N[0]\n",
    "c0 = settings.c0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb4b91",
   "metadata": {},
   "source": [
    "**grid creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ebce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0 - dx, Lx + dx, Nx + 3)  # with ghost cells\n",
    "t = np.linspace(0, (N - 1) * dt, N)\n",
    "x_, t_ = np.meshgrid(x, t, indexing='ij')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e766f",
   "metadata": {},
   "source": [
    "**loading measurements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abac081",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfSources = 2\n",
    "fm = np.zeros((numberOfSources, Nx + 1, N))\n",
    "um = np.zeros((numberOfSources, Nx + 1, N + 1))\n",
    "for i in range(numberOfSources):\n",
    "    fm[i] = np.array(pd.read_hdf(\"measurement1DFWI/source\" + str(i) + \".h5\").values)\n",
    "    um[i] = np.array(pd.read_hdf(\"measurement1DFWI/signal\" + str(i) + \".h5\").values)\n",
    "cm = np.array(pd.read_hdf(\"measurement1DFWI/material.h5\").values)[:, 0]\n",
    "\n",
    "sensorPositions = (0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c7982",
   "metadata": {},
   "source": [
    "**initial conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3afaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = x * 0\n",
    "u1 = x * 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f6110a",
   "metadata": {},
   "source": [
    "## Hyperparameter selection & model/ansatz initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61199f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "if selectModel == \"Linear\":\n",
    "    model = LinearAnsatz(Nx, device)\n",
    "    modelInput = torch.from_numpy(x).unsqueeze(1)  # dummy\n",
    "\n",
    "    # hyperparameters\n",
    "    lr = 2e-2\n",
    "    alpha = -0.5\n",
    "    beta = 0.2\n",
    "    epochs = 3000\n",
    "    costScaling = 1e8\n",
    "    clip = 1e-2\n",
    "\n",
    "elif selectModel == \"FNN\":\n",
    "    model = FNN(1, [100, 100], 1)\n",
    "    modelInput = torch.from_numpy(x).unsqueeze(1)\n",
    "    modelInput = (modelInput - torch.min(modelInput)) / (\n",
    "                torch.max(modelInput) - torch.min(modelInput)) * 2 - 1  # normalize and center input data\n",
    "\n",
    "    # hyperparameters\n",
    "    lr = 1e-2\n",
    "    alpha = -0.5\n",
    "    beta = 0.4  # IMPORTANT PARAMETER  \n",
    "    epochs = 3000\n",
    "    costScaling = 1e8\n",
    "    clip = 1e-2  #1e-2 #1e-3\n",
    "\n",
    "elif selectModel == \"CNN\":\n",
    "    model = CNN()\n",
    "    modelInput = torch.randn((1, 128, 15), device=device)\n",
    "    modelInput = (modelInput - torch.min(modelInput)) / (\n",
    "                torch.max(modelInput) - torch.min(modelInput)) * 2 - 1  # normalize and center input data\n",
    "\n",
    "    # hyperparameters\n",
    "    lr = 1e-2  #2e-3 #2e-3 #2e-2 #5e-3 #1e-2\n",
    "    alpha = -0.5  #-0.2\n",
    "    beta = 0.8  #0.5  \n",
    "    epochs = 3000\n",
    "    costScaling = 1e8\n",
    "    clip = 1e-3  #1e-3\n",
    "\n",
    "print(\"number of parameters: {:d}\".format(\n",
    "    np.sum(np.array([len(list(model.parameters())[i].flatten()) for i in range(len(list(model.parameters())))]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa9cbc",
   "metadata": {},
   "source": [
    "## Optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "lr_lambda = lambda epoch: (beta * epoch + 1) ** alpha\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ba804",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c60bac",
   "metadata": {},
   "source": [
    "**training setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e51073",
   "metadata": {},
   "outputs": [],
   "source": [
    "costHistory = np.zeros(epochs)\n",
    "start = time.perf_counter()\n",
    "start0 = start\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f808a",
   "metadata": {},
   "source": [
    "**training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    cpred = c0 * model(modelInput)\n",
    "    cpred[:, :, :1] = c0  # assuming boundary values to be intact \n",
    "    cpred[:, :, -1:] = c0  # assuming boundary values to be intact\n",
    "    cpred.grad = torch.zeros_like(cpred, device=device)\n",
    "\n",
    "    gradient, cost = FiniteDifference.getAllAdjointSensitivities(u0, u1, fm, cpred[0, 0].detach().numpy(),\n",
    "                                                                 dx, Nx, dt, N, um, sensorPositions)\n",
    "\n",
    "    cpred.grad[0, 0, 1:-1] = torch.from_numpy(gradient)\n",
    "\n",
    "    cpred.backward(\n",
    "        costScaling * cpred.grad)  # explanation: https://web.archive.org/web/20221026061918/https://medium.com/@monadsblog/pytorch-backward-function-e5e2b7e60140\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    costHistory[epoch] = cost\n",
    "\n",
    "    if selectModel == \"Linear\":\n",
    "        model.coefficients.data = model.coefficients.data.clamp(0., 1.)  # clamping instead of sigmoid\n",
    "\n",
    "    if (epoch % 100 == 0):\n",
    "        elapsed_time = time.perf_counter() - start\n",
    "        string = \"Epoch: {}/{}\\t\\tCost function: {:.3E}\\t\\tElapsed time: {:2f}\"\n",
    "        print(string.format(epoch, epochs - 1, costHistory[epoch], elapsed_time))\n",
    "        start = time.perf_counter()\n",
    "\n",
    "print(\"Total elapsed training time: {:2f}\".format(time.perf_counter() - start0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a45d6",
   "metadata": {},
   "source": [
    "**prediction of material distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cpred = c0 * model(modelInput).squeeze().detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df297102",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa847a",
   "metadata": {},
   "source": [
    "**predicted material distribution & true material distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x[1:-1], cpred[1:-1], 'k--', label=\"prediction\")\n",
    "ax.plot(x[1:-1], cm[1:-1], 'r', label=\"ground truth\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$c(x)$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001b944",
   "metadata": {},
   "source": [
    "**learning history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(costHistory, 'k')\n",
    "ax.grid()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"cost\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
